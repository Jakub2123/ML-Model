{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e64603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dzień piąty DWthon 👋 - Hack Outside the Box \n",
    "\n",
    "### Celem jest poznanie, czym jest tak zwany \"aha moment\"!\n",
    "\n",
    "Czy wiesz co to jest \"aha-moment\"? To jest taki moment, kiedy mówisz... \"aha\" 😁. Czyli coś Cię olśniło i rzeczywistość (a przynajmniej jej kawałek) stał się bardziej dla Ciebie zrozumiały.\n",
    "\n",
    "O \"aha-momencie\" można długo mówić, lepiej podam Ci kilka przykładów.\n",
    "\n",
    "\n",
    "### Facebook (7 przyjaciół w 10 dni)\n",
    "Jeśli użytkownik dodaje co najmniej **10 znajomych** w ciągu **pierwszych 7 dni** od rejestracji, wtedy ten użytkownik będzie bardziej zaangażowany i na dłużej zostanie w Facebook.\n",
    "\n",
    "### Dropbox (1 plik, 1 folder, 1 urządzenie)\n",
    "Jeśli użytkownik doda co najmniej jeden plik, jeden folder i zsynchronizuje się z co najmniej jednym urządzeniem, to wtedy ten użytkownik zostanie na dłużej.\n",
    "\n",
    "### LinkedIn - X połączeń w Y dni\n",
    "\n",
    "\n",
    "To są proste reguły, które potrafią opisać najważniejsze, co ma się wydarzyć w firmie, aby firma rosła. Innymi słowy to jest stosowanie wprost reguły 80/20.\n",
    "\n",
    "\n",
    "Trudność polega na tym, że aby znaleźć tę prostą regułę, to... no właśnie, jak można ją znaleźć? Przecież takich prostych reguł może być tysiące lub nawet miliony, zabraknie nam czasu, aby je wszystkie sprawdzić. Tutaj na pomoc nam może przyjść `Machine Learning`.\n",
    "\n",
    "### Zanim zaczniemy | ważne ❗\n",
    "\n",
    "Ankieta numer 5! Każdy dzień DWthon - hack outside the box ma dedykowaną ankietę. Wypełnij ją zanim przejdziesz do nauki. Zajmie Ci to tylko 3 minutki ;) \n",
    "\n",
    "### [Wypełnij ankietę](https://bit.ly/3qxZd9S)  i mierz deltę swego rozwoju :) \n",
    "\n",
    "### Gdzie zadawać pytania ❓ \n",
    "\n",
    "Jeśli napotkasz trudności podczas wykonywania zadań z tego notebooka, to koniecznie napisz w kanale [dwthon_day5](https://bit.ly/3qEBEMv)\n",
    "\n",
    "Pamiętaj, aby szczegółowo doprecyzować, z czym masz problem. Najlepiej wrzuć screen z kodem swoim lub błędem, który widzisz i napisz, którego zadania dotyczy :)\n",
    "\n",
    "%%html\n",
    "<iframe style=\"height:500px;width:100%\" src=\"https://www.youtube.com/embed/EeFJLSS3_x0\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>\n",
    "\n",
    "### Krok po kroku \n",
    "\n",
    "Nagrałem dla Ciebie także materiał wideo \"krok po kroku\". W wideo poniżej znajduje się dokładnie to, co w tym notebooku tylko tłumaczę wszystko, aby ułatwić Ci pracę i zrozumienie zagadnień i zadań :) Obejrzyj, jeśli potrzebujesz takiego dodatkowego wsparcia. \n",
    "\n",
    "%%html\n",
    "<iframe style=\"height:500px;width:100%\" src=\"https://www.youtube.com/embed/7UTzlVkK17k\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>\n",
    "\n",
    "## Biblioteki\n",
    "Potrzebujemy `pandas` i jeszcze trochę więcej innych bibliotek. \n",
    "* `DecisionTreeClassifier` - do trenowania modelu\n",
    "* `sklearn.model_selection` walidacja modelu\n",
    "* `gc` do sprzątania w pamięci RAM\n",
    "\n",
    "Dodatkowo użyjemy nowego bardziej zaawansowanego modelu `xgboost` oraz biblioteki `eli5` do podglądania ważności cech.\n",
    "`from collections import Counter` przyda nam się do wygodnego zliczenia liczby wystąpień (np. ile razy klient kupił produkt x).\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "import eli5 \n",
    "from collections import Counter\n",
    "\n",
    "import gc\n",
    "\n",
    "## Wczytajmy dane\n",
    "\n",
    "df = pd.read_hdf(\"../input/data.h5\")\n",
    "\n",
    "print(df.shape)\n",
    "df.sample(5)\n",
    "\n",
    "## Przygotowujemy dane\n",
    "\n",
    "\n",
    "To jest kod z poprzedniej lekcji. Jedynie poukładamy kod w funkcji, aby łatwiej było nam eksperymentować później.\n",
    "\n",
    "df_customers = (\n",
    "    df[ [\"price_total\", \"customer_id\"] ]\n",
    "    .groupby(\"customer_id\")\n",
    "    .agg(\"sum\")\n",
    "    .reset_index()\n",
    "    .sort_values(by=\"price_total\", ascending=False)\n",
    "    .rename(columns={\"price_total\": \"customer_price_total\"})\n",
    ")\n",
    "\n",
    "\n",
    "df_customers[\"cumsum\"] = df_customers[\"customer_price_total\"].cumsum()\n",
    "value_80prc = int(df[\"price_total\"].sum() * 0.8)\n",
    "df_customers[\"most_revenue_customer\"] = df_customers[\"cumsum\"] < value_80prc\n",
    "\n",
    "\n",
    "top_customers = set(df_customers[ df_customers[\"most_revenue_customer\"] ][\"customer_id\"].unique())\n",
    "\n",
    "del df_customers\n",
    "gc.collect()\n",
    "\n",
    "def feature_engineering(df):\n",
    "    df_customers = (\n",
    "        df\n",
    "        .groupby(\"customer_id\")\n",
    "        .agg(\n",
    "            count_orders=(\"order_id\", lambda x: len(set(x))),\n",
    "            count_unq_products=(\"product_id\", lambda x: len(set(x))),\n",
    "            sum_quantity=(\"quantity\", np.sum),\n",
    "            sum_price_unit=(\"price_unit\", np.sum),\n",
    "            sum_price_total=(\"price_total\", np.sum),\n",
    "            count_unq_countries=(\"country_id\", lambda x: len(set(x))),\n",
    "            prob_canceled=(\"is_canceled\", np.mean)\n",
    "        ).reset_index()\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    return df_customers\n",
    "\n",
    "\n",
    "def get_feats(df_customers, black_list=[\"most_revenue_customer\"]):\n",
    "    feats = list(df_customers.select_dtypes([np.number, bool]).columns)\n",
    "    return [x for x in feats if x not in black_list]\n",
    "\n",
    "def get_X_y(df_customers, top_customers, feats):\n",
    "    df_customers[\"most_revenue_customer\"] = df_customers[\"customer_id\"].map(lambda x: x in top_customers)\n",
    "    \n",
    "    X = df_customers[feats].values\n",
    "    y = df_customers[\"most_revenue_customer\"].values\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def train_and_get_scores(model, X, y, scoring=\"accuracy\", cv=5):\n",
    "\n",
    "    scores = cross_val_score(model, X, y, scoring=scoring, cv=cv)\n",
    "    return np.mean(scores), np.std(scores)\n",
    "\n",
    "## Model 1\n",
    "\n",
    "☝️ Dokładnie to, co zrobiliśmy ostatnio.\n",
    "\n",
    "df_customers = feature_engineering(df)\n",
    "feats = get_feats(df_customers)\n",
    "X, y = get_X_y(df_customers, top_customers, feats)\n",
    "model = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "train_and_get_scores(model, X, y)\n",
    "\n",
    "Mamy wynik 99.9%.\n",
    "\n",
    "Można się cieszyć, ale... tak naprawdę opowiem Ci o jednym mechanizmie, który regularnie stosuję. Nazywam go wahadło.\n",
    "\n",
    "Idea polega na tym, aby najpierw być dużym optymistą i bardzo upraszczać rzeczywistość na początku. \n",
    "Następnie, jak już mamy dobry wynik, to wchodzimy w \"zupełnie inne buty\". \n",
    "Wchodzimy w rolę aktywnego \"krytyka\", który próbuje zrobić wszystko, aby udowodnić, że to, co zrobiliśmy nie ma sensu.\n",
    "Powtarzamy tak w kółko. Robimy kilka iteracji :)\n",
    "Najważniejsze jest to, że dzięki przełączaniu się pomiędzy rolami, można bardzo szybko biec od przodu, ale z drugiej \n",
    "strony mieć poczucie, że to nadal ma sens!\n",
    "\n",
    "## 🧠 Włączmy myślenie krytycznie\n",
    "\n",
    "Na ten moment wykonaliśmy pierwszy krok, czyli optymistyczny i dostaliśmy wynik 99%. \n",
    "Bardzo dobrze, ale... Problem polega na tym, że `price_unit_total`jest zbyt mocną cechą. \n",
    "Czyli ta cecha wprost mówi, czy klient należy do segmentu `top_customers` czy nie. \n",
    "Dlatego teraz musimy co najmniej tę cechę wyłączyć i sprawdzić, jak zachowa się model.\n",
    "\n",
    "Wystarczy dodać `sum_price_total` do listy, którą będziemy ignorować. \n",
    "\n",
    "Zobacz 👀.\n",
    "\n",
    "\n",
    "## Model 2\n",
    "\n",
    "df_customers = feature_engineering(df)\n",
    "feats = get_feats(df_customers, black_list=[\"most_revenue_customer\", \"sum_price_total\"])\n",
    "X, y = get_X_y(df_customers, top_customers, feats)\n",
    "model = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "train_and_get_scores(model, X, y)\n",
    "\n",
    "Jak widzisz, jakość modelu nam spadła do 77%. Z jednej strony smutna sprawa 😂, ale z drugiej strony używamy modelu ML, aby znajdował mniej oczywiste zależności. Bo te oczywiste człowiek sam łatwo znajdzie sam 🤦‍♂️.\n",
    "\n",
    "\n",
    "### Myślenie optymistyczne\n",
    "To teraz wróćmy znów do bycia optymistą. Pamiętasz na czym polega zasada wahadła? Wahamy się tam i z powrotem ;) \n",
    "\n",
    "\n",
    "Można zmienić model na bardziej zaawansowany i to powinno poprawić wynik. Użyjmy `xgboost`.\n",
    "Ta nazwa może Ci nic nie mówić i to jest ok na tym etapie 👌.\n",
    "\n",
    "## Model 3\n",
    "\n",
    "Zwróć uwagę, że zmieniła się ta linijka: `model = xgb.XGBClassifier(max_depth=5, n_estimators=50, learning_rate=0.3)`.\n",
    "\n",
    "df_customers = feature_engineering(df)\n",
    "feats = get_feats(df_customers, black_list=[\"most_revenue_customer\", \"sum_price_total\"])\n",
    "X, y = get_X_y(df_customers, top_customers, feats)\n",
    "model = xgb.XGBClassifier(max_depth=5, n_estimators=50, learning_rate=0.3)\n",
    "\n",
    "train_and_get_scores(model, X, y)\n",
    "\n",
    "## Mamy wynik 81%.\n",
    "\n",
    "Spróbujmy zrobić pierwszą interpretację modelu i zobaczyć, co wg nieg0 jest ważne.\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "eli5.show_weights(model, feature_names=feats)\n",
    "\n",
    "### Wstępnie wnioski:\n",
    "#### TOP3 \n",
    "- `sum_quantity` brzmi jako najważniejsza cecha*\n",
    "- `count_orders`\n",
    "- `sum_price_unit`\n",
    "\n",
    "Wyglada na to, że cecha `count_unq_countries` jest mało przydatna.\n",
    "\n",
    "\n",
    "☝️ Trzeba uważać na to, co jest \"ważne\", bo doświadczenie pokazuje, że to może być dość zmienne i w tej zmienności\n",
    "trzeba nauczyć się poruszać.\n",
    "\n",
    "\n",
    "## Następny krok\n",
    "\n",
    "Możemy teraz trochę pofilozofować nad tymi kilkoma cechami, ale to jest mało istotne. \n",
    "Te cechy same w sobie są dość oczywiste. Nie ma poczucia \"dużej\" wartości dodanej. \n",
    "\n",
    "Ciekawostką okazało się, że `sum_quantity` jest istotna. Tylko tutaj też nie ma dużego zaskoczenia.\n",
    "\n",
    "Wygenerujmy zatem więcej cech, niech model znajdzie na co warto zwrócić naszą uwagę :) \n",
    "\n",
    "\n",
    "## Produkty\n",
    "\n",
    "\n",
    "Możemy dodać dla każdego produktu osobną kolumnę i jako wartość w tej kolumnie dodać,\n",
    "ile produktów już było kupionych (czyli suma).\n",
    "W ten sposób chcemy znaleźć, które produkty są \"najciekawsze\", warte tego, aby zwrócić na nie uwagę.\n",
    "\n",
    "☝️ Oczywiście możemy sprawdzić każdy produkt manualnie, ale mamy ich ponad 3.8k, może to nam trochę zająć czasu. \n",
    "Użyjmy lepiej do tego ML, będzie szybciej, sprawniej i efektywniej.\n",
    "\n",
    "Tylko najpierw trzeba przygotować dane. Zmieńmy naszą funkcję `feature_engineering`. \n",
    "\n",
    "def feature_engineering(df):\n",
    "    \n",
    "    def counter(vals):\n",
    "        cntr = Counter()\n",
    "        cntr.update(vals)\n",
    "        return cntr\n",
    "    \n",
    "    df_customers = (\n",
    "        df\n",
    "        .groupby(\"customer_id\")\n",
    "        .agg(\n",
    "            count_orders=(\"order_id\", lambda x: len(set(x))),\n",
    "            count_unq_products=(\"product_id\", lambda x: len(set(x))),\n",
    "            count_by_products=(\"product_id\", lambda x:  counter(x) ),\n",
    "            sum_quantity=(\"quantity\", np.sum),\n",
    "            sum_price_unit=(\"price_unit\", np.sum),\n",
    "            sum_price_total=(\"price_total\", np.sum),\n",
    "            count_unq_countries=(\"country_id\", lambda x: len(set(x))),\n",
    "            prob_canceled=(\"is_canceled\", np.mean)\n",
    "        ).reset_index()\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return df_customers\n",
    "\n",
    "\n",
    "df_customers  = feature_engineering(df)\n",
    "df_customers.head()\n",
    "\n",
    "#Jak widzisz pojawiła się nowa kolumna `count_by_products`. W środku jest słownik. Zobaczmy dokładniej 👀.\n",
    "\n",
    "df_customers[\"count_by_products\"]\n",
    "\n",
    "W praktyce to oznacza, że  `customer_id=0` kupił np. `product_id=0` - 89 razy, `product_id=1` - 73 razy, `product_id=3` - 68 razy itd.\n",
    "\n",
    "\n",
    "Fajnie byłoby nam wypakować słownik do osobnych kolumn, na szczęście da się to zrobić bardzo łatwo. \n",
    "⌛️ Tylko poczekaj chwilkę na wykonanie.\n",
    "\n",
    "df_count_products = df_customers[\"count_by_products\"].apply(pd.Series).fillna(-1)\n",
    "df_count_products.columns = [\"product_{}\".format(x) for x in df_count_products.columns]\n",
    "\n",
    "df_count_products.head(5)\n",
    "\n",
    "Mamy teraz osobny `dataframe` z 3878 kolumnami. Każda kolumna to jest `product_id`. Wartość -1 oznacza brak informacji,\n",
    "czyli  klient nie kupował tego produktu, natomiast każda inna liczba (większa niż 0) oznacza, ile razy ten produkt \n",
    "był kupiony (to jest trochę optymistyczne zdanie, ale na razie możemy przyjąć, że jest ok).\n",
    "\n",
    "#☝️ Zwróć uwagę, że pojawiła się linijka zmiany nazwy produktu. \n",
    "`df_count_products.columns = [\"product_{}\".format(x) for x in df_count_products.columns]` \n",
    "#W tym miejscu robimy bardzo prostą rzeczy, zamiast samego ID, np. 0 czy 2, dodajemy przedrostek, \n",
    "#aby kolumna nazywała się  `product_0` czy `product_2`. To nam przyda się za chwilę.\n",
    "\n",
    "\n",
    "### Następny krok\n",
    "\n",
    "Połączmy `df_count_products` z `df_customers` i wytrenujmy model.\n",
    "Aby to połączyć użyjemy konstrukcji `concat()`. Wynikiem będzie to, że dokleimy to \"z boku\".\n",
    "Innymi słowy liczba wierszy zostanie taka sama, liczba kolumn powiększy się o 3878 😱.\n",
    "Model pewnie ucieszy się, będzie miał, co optymalizować.\n",
    "\n",
    "Łączymy!\n",
    "\n",
    "df_customers = pd.concat([df_customers, df_count_products], axis=1)\n",
    "df_customers.shape\n",
    "\n",
    "Tak jak spodziewaliśmy się, liczba wierszy została taka sama - 5879 (bo liczba wierszy to są klienci, nowych klientów nie przybyło). Liczba kolumn wzrosła nam do 3887. Możesz o tym pomyśleć, że teraz każdy klient posiada 3887 cech, czyli charakterystyk.\n",
    "\n",
    "## 🤖 Czas na trenowanie modelu\n",
    "\n",
    "Najpierw sprawdźmy, czy jakość modelu się nam poprawiła.\n",
    "\n",
    "Uwaga! Model potrzebuje czasu na trenowanie, więc możesz spokojnie przez chwilę odpocząć. Model wykonuje \"prostą\"\n",
    "i powtarzalną pracę, natomiast po Twojej stronie jest myślenie koncepcyjnie. \n",
    "Przyzwyczajaj się, to jest przyszłość, która już do nas przyszła :)\n",
    "\n",
    "#df_customers = feature_engineering(df)\n",
    "feats = get_feats(df_customers, black_list=[\"most_revenue_customer\", \"sum_price_total\"])\n",
    "X, y = get_X_y(df_customers, top_customers, feats)\n",
    "model = xgb.XGBClassifier(max_depth=5, n_estimators=50, learning_rate=0.3)\n",
    "\n",
    "train_and_get_scores(model, X, y)\n",
    "\n",
    "Jakość modelu poprawiła się, mamy już ~85%. \n",
    "\n",
    "Przypomnę, że same drzewa decyzyjne dały nam 77%. XGBoost na podstawowych cechach dał nam 81% i teraz mamy 85%.\n",
    "\n",
    "Może się wydawać, że to słabo, bo mieliśmy 99,9%. Chcę taki wynik znowu! \n",
    "\n",
    "Być może to jest przykra wiadomość, ale często model \"stopuje\" się właśnie w okolicy 60-70% i potem trzeba naprawdę\n",
    "postarać się, aby wycisnąć więcej. No chyba, że użyjemy oczywistych zależności, ale to jest mało ciekawe.\n",
    "Lepiej jednak pozwolić modelowi znaleźć coś, co może zaskoczyć.\n",
    "\n",
    "Wytrenujmy model teraz niezależnie, aby można było zajrzeć i sprawdzić, co dla niego jest ważne.\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "eli5.show_weights(model, feature_names=feats, top=50)\n",
    "\n",
    "#No teraz już przynajmniej mamy na co popatrzeć :). Widać, że ważność produktu `product_545` oraz `product_99` jest \n",
    "#ponad `count_orders`. Oczywiście, tak jak mówiłem, tutaj trzeba ostrożnie wyciągać wnioski. \n",
    "#Natomiast to, co jest jednoznaczne to to, że `product_id=545` zasłużył na to, aby zwrócić na niego uwagę 🥳. \n",
    "#To sprawdźmy :).\n",
    "\n",
    "customer_ids_by_product = set(df[ df[\"product_id\"] == 545 ][\"customer_id\"].unique())\n",
    "len(customer_ids_by_product )\n",
    "\n",
    "#Ten produkt kupiło nie tak wielu klientów, tylko 168. Sprawdźmy, ilu z nich należy do segmentu `most_revenue_customer`.\n",
    "\n",
    "df_customers[ df_customers.customer_id.isin(customer_ids_by_product) ][\"most_revenue_customer\"].mean()\n",
    "\n",
    "#No widzimy, że mamy 42% klientów, którzy kupili co najmniej `product_id=545` i należą do segmentu `most_revenue_customer`.\n",
    "#Przypomnę, że normalnie mamy 22% klientów, którzy należą do segmentu `most_revenue_customer`.\n",
    "\n",
    "df_customers[\"most_revenue_customer\"].mean()\n",
    "\n",
    "#Możemy na szybko postawić hipotezę (do zbadania) -  jeśli klient kupił `product_id=545` to prawdopodobieństwo, \n",
    "#że będzie należał do segmentu `most_revenue_customer` prawie podwaja się (od 23% do 42%). Brzmi jako \"aha moment\". \n",
    "#Tę hipotezę warto jeszcze zbadać dokładniej, ale jeżeli ona faktycznie działa, to oznacza, że warto sprawić, \n",
    "#aby więcej ludzi kupowało właśnie `product_id=545`.\n",
    "\n",
    "#### Sprawdźmy, ile kosztuje ten produkt. Może to jakiś luksus ⚜️.\n",
    "\n",
    "df[ df.product_id == 545 ][\"price_unit\"].value_counts()\n",
    "\n",
    "Z ceną tego produktu bywa różnie, ale najczęściej cena jednostkowa, to jedynie 1,25 lub 3,9 😱. Taki ciekawy wniosek udało się znaleźć w tak łatwy sposób.\n",
    "\n",
    "## Zadanie 5.1\n",
    "\n",
    "\n",
    "Twoim zadaniem jest zrobić podobną analizę dla produktu.\n",
    "\n",
    "\n",
    "### 💡 Podpowiedzi: \n",
    "\n",
    "1. Przygotuj `df_products`\n",
    "2. Dodaj więcej cech, przed dodaliśmy `product_id`, ale możesz zrobić symetryczne lub wymyśl coś innego (może `order_id`) lub jeszcze coś innego, jest sporo pomysłów :) \n",
    "3. Wytrenuj model. \n",
    "4. Zobacz, co dla modelu było najbardziej istotne.\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "Jak **wykonasz** zadanie, należy zrobić:\n",
    "\n",
    "1. Zrzut ekranu na którym widać rozwiązania, wtedy dostaniesz bonus :)\n",
    "2. Wrzucić rozwiązanie na slacku do pokoju **[#dwthon_day5_done](https://bit.ly/3teY3l8)**\n",
    "3. Dostać bonus za dobrą robotę 💪 i jutro będzie kolejna porcja.\n",
    "\n",
    "*Uwaga! Jeśli masz problem z jakimś zadaniem, czegoś nie wiesz, to pamiętaj, że możesz zadawać pytania! Na tym polega nauka :) Pytania związane z 2 dniem DWthon zadawaj w kanale [#dwthon_day5](https://bit.ly/3qEBEMv)*.\n",
    "\n",
    "## 🧠 Włączmy myślenie krytycznie\n",
    "\n",
    "\n",
    "Ta cała nasza analiza była oparta na `price_total`, czyli przychodach. Co ze zwrotami? Być może nastąpił czas nieco bardziej wejść do króliczej nory?\n",
    "\n",
    "Na co jeszcze warto zwrócić krytyczną uwagę?  Podpowiem, że jeszcze jest sporo rzeczy ;)\n",
    "\n",
    "## 😇 Włączmy myślenie kreatywne\n",
    "\n",
    "Pomyśl, jak możesz wykorzystać tę wiedzę, którą tutaj udało Ci się zdobyć?\n",
    "\n",
    "Najlepiej, aby padły przykłady z Twojego podwórka. Jeśli nie masz (ale pomyśl, bo to tylko może się wydawać, że nie ma) to pomyśl o swoim otoczeniu.\n",
    "\n",
    "Od razu powiem, że nie chodzi tylko o e-commerce. To może być dowolna branża. Reguła 80/20 jest uniwersalna. To samo dotyczy \"aha-momentów\".\n",
    "\n",
    "## 🤝🗣️ Pomyśl o kooperacji i komunikacji\n",
    "\n",
    "#### ☝️ Podziel się swoimi przemyśleniami na slacku **[#dwthon_day5_ideas](https://bit.ly/3qFcb5R)**. Jeśli masz pomysł, ale nie masz kodu - poproś na slacku o pomoc, aby ktoś pomógł Ci napisać kod. Natomiast jeśli masz kod, to koniecznie podziel się. Dzięki temu ktoś inny będzie w stanie łatwo powtórzyć i podzielić się swoimi przemyśleniami. Dzięki temu każdy zyskuje :).\n",
    "\n",
    "\n",
    "%%html\n",
    "<iframe style=\"height:500px;width:100%\" src=\"https://www.youtube.com/embed/qC2MZcjGfcM\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>\n",
    "\n",
    "## Twój Feedback i delta rozwoju \n",
    "\n",
    "Daj mi znać koniecznie, co sprawiło Ci przyjemność, co trudność oraz czego udało się nauczyć w tej krótkiej [ankiecie](https://bit.ly/3rEnOLD). Pozwoli mi ona ulepszyć zadania, a Tobie lepiej trakować swój rozwój: win-win 😇\n",
    "\n",
    "### 🎁 Opublikuj rozwiązania, czeka na Ciebie bonus \n",
    "\n",
    "1. Wrzucić rozwiązanie na slacku do pokoju [#dwthon_day5_done](https://bit.ly/3teY3l8)\n",
    "2. Otrzymasz bonusy, a w nich m.in. kolejną lekcję wideo z naszego najlepszego programu nauki [DS & ML w praktyce](\n",
    "https://dataworkshop.eu/pl/practical-machine-learning)\n",
    "3. Umiesz więcej ;) \n",
    "\n",
    "## 💪 Pochwal się światu, że DWthon za Tobą 💪 \n",
    "\n",
    "Udało Ci się! Jesteś na mecie, koniecznie powiedz o tym innym. Być może kogoś to zmotywuje do działania, a dodatkowo warto mówić głośno o nowych umiejętnościach i doświadczeniach, bo nigdy nie wiesz, jaka furtka może się otworzyć ;) \n",
    "\n",
    "Pamiętaj o #dwthon #hackoutsidethebox ;) \n",
    "\n",
    "Śmiało nas oznaczaj, będzie nam miło :))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
